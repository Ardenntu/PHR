{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"TMY__II-ETSd"},"outputs":[],"source":["import numpy as np\n","import os\n","import tensorflow as tf\n","from keras.models import Model\n","from keras.regularizers import l2\n","#from keras import optimizers\n","from keras.layers import Input, Reshape, Dense, Dropout, Add, Layer, MultiHeadAttention, Embedding, LSTM, Bidirectional\n","import keras.backend as K\n","from spektral.layers import GraphSageConv\n","\n","import random, pickle, math, h5py, heapq\n","import scipy.sparse as sp\n","from scipy.spatial.distance import cosine\n","from sklearn.preprocessing import normalize\n","from sklearn import random_projection\n","\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","\n","os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n","\n","gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=1)\n","sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))\n","\n","tf.compat.v1.keras.backend.set_session(sess)\n","\n","\n","num_epoch = 700\n","text_embedding_size = 300\n","feature_size = 300\n","\n","num_user = 1000\n","num_tags = 3896\n","seq_length = 49    # max length of text sequence\n","dim_k = 100\n","\n","# post-tag attention\n","top_u_post_num = 5\n","top_o_post_num = 10\n","top_gamma_tag = 10\n","post_embedding_size =300\n","tag_embedding_size =300\n","\n","support = 1\n","today=\"0907-1\"\n","\n","num_user_per_batch = 23\n","num_post_per_batch = 500\n","num_batch = 40\n","value = 0.9\n","date_num = \"0116\"\n","\n","tf.config.list_physical_devices()"]},{"cell_type":"markdown","metadata":{"id":"DpBxCnAxETSi"},"source":["#### Utils"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kzRbQ-X2ETSk"},"outputs":[],"source":["def one_hot_encoding(inputs, num_total):\n","    output = np.zeros((len(inputs),num_total),dtype=np.int32)\n","    for i in range(len(inputs)):\n","        for t in inputs[i]:\n","            output[i][t]=1\n","\n","    return output\n","\n","def batch_train_label(tag_total, idx_train_array, test_array_len):\n","\tnum_tags = 3896\n","\tbatch_label = []\n","\tfor i in range(len(idx_train_array)):\n","\t\ttmp = np.zeros(num_tags, dtype=int)\n","\t\ttmp[np.array(tag_total[idx_train_array[i]], dtype=np.int32)] = 1\n","\t\tbatch_label.append(tmp)\n","\n","\tfor j in range(test_array_len):\n","\t\tbatch_label.append(np.zeros(num_tags, dtype=int))\n","\n","\tbatch_label = np.array(batch_label)\n","\treturn batch_label\n","\n","def batch_test_label(tag_total, idx_test_array):\n","\tnum_tags = 3896\n","\tbatch_label = []\n","\tfor i in range(len(idx_test_array)):\n","\t\ttmp = np.zeros(num_tags, dtype=int)\n","\t\ttmp[np.array(tag_total[idx_test_array[i]], dtype=np.int32)] = 1\n","\t\tbatch_label.append(tmp)\n","\n","\tbatch_label = np.array(batch_label)\n","\treturn batch_label\n","\n","def adj_by_newcosine(feature,threshold):\n","\n","\tvectors = np.array(feature)\n","\tsimilarity = np.dot(vectors, vectors.T)\n","\tdel vectors\n","\tinv_square_mag = 1 / (np.diag(similarity))\n","\tinv_square_mag[np.isinf(inv_square_mag)] = 0\n","\tinv_mag = np.sqrt(inv_square_mag)\n","\tcosine = similarity * inv_mag\n","\tdel similarity, inv_square_mag\n","\tcosine = cosine.T * inv_mag\n","\n","\tscore = threshold\n","\tqueries = np.zeros(feature.shape[0], dtype=int)\n","\tfor i in range(feature.shape[0]):\n","\t\tqueries[i] = i\n","\n","\trow = []\n","\tcol = []\n","\tdata = []\n","\tfor sim,query in zip(cosine, queries):\n","\t\tsim = list(sim)\n","\t\ttmp = heapq.nlargest(2, sim)\n","\t\tif float(tmp[1]) <= score:\n","\t\t\tcontinue\n","\t\telse:\n","\t\t\tsort_cosine = sorted(enumerate(sim), reverse=True, key=lambda x: x[1])\n","\t\t\tfor item in sort_cosine:\n","\t\t\t\tif query == int(item[0]):\n","\t\t\t\t\tcontinue\n","\t\t\t\telse:\n","\t\t\t\t\tif float(item[1]) > score:\n","\t\t\t\t\t\trow.append(query)\n","\t\t\t\t\t\tcol.append(int(item[0]))\n","\t\t\t\t\t\tdata.append(float(item[1]))\n","\t\t\t\t\telse:\n","\t\t\t\t\t\tbreak\n","\n","\tadj = sp.coo_matrix((data, (row, col)), shape=(feature.shape[0], feature.shape[0]))\n","\tadj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n","\n","\tdel inv_mag, cosine, queries, row, col, data\n","\n","\treturn adj\n","\n","def img_adj_by_newcosine(img_feature, threshold):\n","\tedges = []\n","\ttmp_img_feature = []\n","\tfor i in range(img_feature.shape[0]):\n","\t\ttmp = img_feature[i].reshape(1,-1)\n","\t\ttmp_img_feature.append(tmp)\n","\ttmp_img_feature = np.squeeze(np.array(tmp_img_feature))\n","\n","\ttransformer = random_projection.GaussianRandomProjection()\n","\tnew_img_feature = transformer.fit_transform(tmp_img_feature)\n","\tdel transformer, tmp_img_feature\n","\n","\tadj = adj_by_newcosine(new_img_feature,threshold)\n","\n","\treturn adj\n","\n","# true if idx is in batch training list\n","def sample_mask(idx, l):\n","    mask = np.zeros(l)\n","    mask[idx] = 1\n","    return np.array(mask, dtype=bool)\n","\n","def normalize_adj(adj, symmetric=True):\n","\tif symmetric:\n","\t\td = sp.diags(np.power(np.array(adj.sum(1)), -0.5).flatten(), 0)\n","\t\ta_norm = adj.dot(d).transpose().dot(d).tocsr()\n","\telse:\n","\t\td = sp.diags(np.power(np.array(adj.sum(1)), -1).flatten(), 0)\n","\t\ta_norm = d.dot(adj).tocsr()\n","\treturn a_norm\n","\n","def preprocess_adj(adj, symmetric=True):\n","\tadj = adj + sp.eye(adj.shape[0])\n","\tadj = normalize_adj(adj, symmetric)\n","\treturn adj\n","\n","def myLossFunc(y_true, y_pred):\n","\tprobs_log = -K.log(y_pred)\n","\tloss = K.mean(K.sum(probs_log*tf.cast(y_true, tf.float32), axis=-1))\n","\treturn loss\n","\n","def evaluator(y_true, y_pred, top_K):\n","\tacc_count = 0\n","\tprecision_K = []\n","\trecall_K = []\n","\tf1_K = []\n","\n","\tfor i in range(y_pred.shape[0]):\n","\t\ttop_indices = y_pred[i].argsort()[-top_K:]\n","\t\t#print(i, top_indices)\n","\t\tif np.sum(y_true[i, top_indices]) >= 1:\n","\t\t\tacc_count += 1\n","\t\tp = np.sum(y_true[i, top_indices]) / top_K\n","\t\tr = np.sum(y_true[i, top_indices]) / np.sum(y_true[i, :])\n","\t\tprecision_K.append(p)\n","\t\trecall_K.append(r)\n","\t\tif p != 0 or r != 0:\n","\t\t\tf1_K.append((2 * (p * r)) / (p + r))\n","\t\telse:\n","\t\t\tf1_K.append(0)\n","\tacc_K = acc_count * 1.0 / y_pred.shape[0]\n","\tmp = np.mean(np.array(precision_K))\n","\tmr = np.mean(np.array(recall_K))\n","\tif mp+mr !=0:\n","\t\tf1 = 2*mp*mr/(mp+mr)\n","\telse:\n","\t\tf1 = 0\n","\n","\t#return acc_K, np.mean(np.array(precision_K)), np.mean(np.array(recall_K)), np.mean(np.array(f1_K))\n","\treturn acc_K, np.mean(np.array(precision_K)), np.mean(np.array(recall_K)), np.mean(np.array(f1_K)), f1\n","def zero_padding(X, seq_length):\n","\tX_ = []\n","\tfor x in X:\n","\t\trow = list(x)[:seq_length] + [0] * max(seq_length-len(x), 0)\n","\t\tX_.append(np.array(row)*1.0)\n","\treturn np.array(X_).astype(int)\n","\n","\n","def get_batch_feature(batch_train_id,text_id_total):\n","\n","    h5f = h5py.File(\"Preprocess_data/dataset_%s.h5\"%(today), \"r\")\n","    vgg_h5f = h5py.File(\"TAGNet/insta_imgFeat_%s.h5\"%(today), \"r\")\n","\n","    train_img = []\n","    train_text = []\n","    train_u_post = []\n","    train_o_post = []\n","    train_u_tag = []\n","    train_o_tag = []\n","    train_text_id = []\n","\n","    for id in batch_train_id:\n","        train_img.append(h5f['img_feature'][id])\n","        #train_img.append(vgg_h5f[ids_total[id]])\n","        train_text.append(h5f['bert_feature'][id])\n","        train_u_post.append(h5f['u_post_feature'][id])\n","        train_o_post.append(h5f['o_post_feature'][id])\n","        train_u_tag.append(h5f['u_tag_feature'][id])\n","        train_o_tag.append(h5f['o_tag_feature'][id])\n","        train_text_id.append(text_id_total[id])\n","\n","    #np.array(np.squeeze(train_img, axis=1))\n","    return np.array(train_img),np.array(train_text), np.array(train_u_post), np.array(train_o_post), np.array(train_u_tag), np.array(train_o_tag), np.array(train_text_id)"]},{"cell_type":"markdown","metadata":{"id":"1WC0dSpmETSl"},"source":["### Models"]},{"cell_type":"markdown","metadata":{"id":"HtDC-SpeETSm"},"source":["#### Layer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"783comKLETSm"},"outputs":[],"source":["class BatchMemory(Layer):\n","    def __init__(self, num_proposals, input_dim, num_slot, memory_size, n_heads,**kwargs):\n","        super(BatchMemory, self).__init__(**kwargs)\n","        self.num_proposals = num_proposals # num_days\n","        self.input_dim = input_dim # == memory dimension d\n","        self.num_slot = num_slot # number of memory slot K\n","        self.memory_size = memory_size # memory dimension d\n","        self.n_heads = n_heads # read out number\n","        self.attention_dim = input_dim # attention_dim\n","\n","        #self.denseFeature = Dense(self.num_slot, activation=\"tanh\", use_bias = False)\n","        self.denseErase = Dense(self.memory_size, activation=\"tanh\", use_bias=True)\n","        self.denseRead = Dense(self.memory_size, activation=\"tanh\", use_bias=True)\n","\n","        self.denseAdd = Dense(self.memory_size, activation=\"tanh\", use_bias=True)\n","        self.multi_head_attention = MultiHeadAttention(num_heads=5, key_dim=64)\n","        #self.cos = cosineSimilarity(dim=0)\n","\n","    def build(self, input_shape):\n","        self.key_matrix = self.add_weight(name=\"key_matrix\",\n","\t\t\t\t\t\t\t\t\tinitializer=\"RandomNormal\",\n","\t\t\t\t\t\t\t\t\t# initializer=\"ones\",\n","\t\t\t\t\t\t\t\t\tshape=( self.memory_size, self.num_slot), # (d, K)\n","\t\t\t\t\t\t\t\t\ttrainable=True)\n","        self.mem_matrix = self.add_weight(name=\"mem_matrix\",\n","\t\t\t\t\t\t\t\t\tinitializer=\"RandomNormal\",\n","\t\t\t\t\t\t\t\t\t# initializer=\"ones\",\n","\t\t\t\t\t\t\t\t\tshape=( self.num_slot, self.memory_size), # (K, d)\n","\t\t\t\t\t\t\t\t\ttrainable=True)\n","    # batch_size = 470\n","    # num_proposal\n","    # memeory_size = 512\n","\n","    def call(self, inputs):\n","\n","        loss = 0.0\n","        count = 0\n","\n","        inputs.set_shape([num_post_per_batch,49,feature_size])\n","\n","        c_vectors = tf.reshape(inputs, (-1, self.input_dim))  # Reshape inputs to (batch_size * num_proposals, input_dim)\n","        #extract_c_vectors = tf.expand_dims(c_vectors, axis=-1)  # Add extra dimension at the end: (batch_size * num_proposals, input_dim, 1)\n","        inner_product = tf.matmul(c_vectors, self.key_matrix) # (batch_size * num_proposals, num_slot)\n","\n","        filter_length = tf.sqrt(tf.reduce_sum(tf.square(c_vectors), axis=1, keepdims=True))  # (batch_size * num_proposals, 1)\n","        key_length = tf.sqrt(tf.reduce_sum(tf.square(self.key_matrix), axis=0, keepdims=True))  # (num_slot, 1)\n","\n","        cosine_similarity= tf.math.divide(inner_product,filter_length * key_length)\n","\n","        cosine_similarity_mul = cosine_similarity * 100\n","        correlation_weight = tf.nn.softmax(cosine_similarity_mul, axis=0)\n","        correlation_weight_mask = tf.where(correlation_weight < 1e-10, tf.zeros_like(correlation_weight), correlation_weight)\n","        # (batch_size * num_proposals, num_slot)\n","        correlation_weight_final = tf.clip_by_value(correlation_weight_mask * cosine_similarity, clip_value_min=0, clip_value_max=tf.float32.max)\n","        correlation_weight_final = tf.expand_dims(correlation_weight_final, axis = 2)  # (batch_size * num_proposals, num_slot, 1)\n","\n","        erase_vector = self.denseErase(c_vectors)  # (batch_size * num_proposals, memory_size)\n","        erase_vector = tf.sigmoid(erase_vector)\n","        erase_vector = tf.expand_dims(erase_vector, axis = 1) # (batch_size * num_proposals, 1, memory_size)\n","\n","        add_vector = self.denseAdd(c_vectors)  # (batch_size * num_proposals, memory_size)\n","        add_vector = tf.tanh(add_vector)\n","        add_vector = tf.expand_dims(add_vector, axis = 1)\n","\n","        erase_mul = tf.matmul(correlation_weight_final, erase_vector)  # (batch_size * num_proposals, num_slot, memory_size)\n","\n","        expanded_memory = tf.expand_dims(self.mem_matrix, axis=0)\n","        repeated_memory = tf.repeat(expanded_memory, repeats=(num_post_per_batch*49), axis=0)  # (batch_size * num_proposals, num_slot, memory_size)\n","\n","        erase = repeated_memory * (1 - erase_mul)  # (num_slot, memory_size) * (memory_size, batch_size * num_proposals)\n","        add = tf.matmul(correlation_weight_final, add_vector)  # (batch_size * num_proposals, num_slot, memory_size)\n","\n","        updated_value = erase + add  # (batch_size * num_proposals, num_slot, memory_size) (23030,49,64)\n","\n","        read_key = self.denseRead(c_vectors) # (batch_size * num_proposals, memory_size) (23030,64)\n","        read_key= tf.expand_dims(read_key,axis=1) #(23030,64,1)\n","\n","        inner_product = tf.matmul(read_key, self.key_matrix) #(233030,1,49)\n","\n","        filter_length = tf.sqrt(tf.reduce_sum(tf.square(read_key), axis=-1, keepdims=True)) #(23030,1,1)\n","        #memory_length = tf.sqrt(tf.reduce_sum(tf.square(updated_value), axis=-1, keepdims=True)) #(23030,49,1)\n","        cosine_similarity= tf.math.divide(inner_product,filter_length * key_length) #(23030,1,49)\n","        #updated_value= tf.transpose(updated_value,perm=[0,2,1])\n","\n","        memory_embedding = tf.matmul(cosine_similarity,updated_value)\n","\n","        memory_embedding = tf.math.l2_normalize(memory_embedding, axis=0)\n","\n","\n","        new_inputs = tf.reshape(memory_embedding, (inputs.shape[0], inputs.shape[1], self.memory_size))  # Reshape back to (batch_size, num_proposals, memory_size * n_heads)\n","        #tf.tensor_scatter_nd_update(inputs, updates, memory_embedding)\n","\n","        #new_inputs = tf.where(tf.math.is_nan(new_inputs), tf.zeros_like(new_inputs), new_inputs)\n","\n","        return new_inputs\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-vnVAdcFETSn"},"outputs":[],"source":["class proposal_Attention(Layer):\n","\tdef __init__(self, **kwargs):\n","\n","\n","\t\tsuper(proposal_Attention, self).__init__(**kwargs)\n","\n","\n","\tdef build(self, input_shape):\n","\n","\t\tif not isinstance(input_shape, list):\n","\t\t\traise ValueError('A Co-Attention_para layer should be called '\n","\t\t\t\t\t\t\t\t'on a list of inputs.')\n","\t\tif len(input_shape) != 2:\n","\t\t\traise ValueError('A Co-Attention_para layer should be called on a list of 2 inputs.'\n","\t\t\t\t\t\t\t\t'Got '+str(len(input_shape))+'inputs.')\n","\t\tself.img_emb_size = input_shape[0][-1] # 512/300\n","\t\tself.emb_size = input_shape[1][-1] # 300 embedding size\n","\t\tself.num_proposal = input_shape[1][1] # 49\n","\n","\t\tself.Wu = self.add_weight(name=\"Wu\",\n","\t\t\t\t\t\t\t\t\tinitializer=\"random_normal\",\n","\t\t\t\t\t\t\t\t\t# initializer=\"ones\",\n","\t\t\t\t\t\t\t\t\tshape=(self.emb_size, self.img_emb_size),\n","\t\t\t\t\t\t\t\t\ttrainable=True)\n","\n","\t\tself.Wl = self.add_weight(name=\"Wl\",\n","\t\t\t\t\t\t\t\t\tinitializer=\"random_normal\",\n","\t\t\t\t\t\t\t\t\t# initializer=\"ones\",\n","\t\t\t\t\t\t\t\t\tshape=(self.emb_size, self.emb_size),\n","\t\t\t\t\t\t\t\t\ttrainable=True)\n","\t\tself.Wr = self.add_weight(name=\"Wr\",\n","\t\t\t\t\t\t\t\t\tinitializer=\"random_normal\",\n","\t\t\t\t\t\t\t\t\t# initializer=\"ones\",\n","\t\t\t\t\t\t\t\t\tshape=(self.emb_size, self.emb_size),\n","\t\t\t\t\t\t\t\t\ttrainable=True)\n","\t\tself.Wu2 = self.add_weight(name=\"Wu2\",\n","\t\t\t\t\t\t\t\t\tinitializer=\"random_normal\",\n","\t\t\t\t\t\t\t\t\t# initializer=\"ones\",\n","\t\t\t\t\t\t\t\t\tshape=(self.emb_size, self.img_emb_size),\n","\t\t\t\t\t\t\t\t\ttrainable=True)\n","\n","\t\tself.Wl2 = self.add_weight(name=\"Wl2\",\n","\t\t\t\t\t\t\t\t\tinitializer=\"random_normal\",\n","\t\t\t\t\t\t\t\t\t# initializer=\"ones\",\n","\t\t\t\t\t\t\t\t\tshape=(self.emb_size, self.emb_size),\n","\t\t\t\t\t\t\t\t\ttrainable=True)\n","\t\tself.Wr2 = self.add_weight(name=\"Wr2\",\n","\t\t\t\t\t\t\t\t\tinitializer=\"random_normal\",\n","\t\t\t\t\t\t\t\t\t# initializer=\"ones\",\n","\t\t\t\t\t\t\t\t\tshape=(self.emb_size, self.emb_size),\n","\t\t\t\t\t\t\t\t\ttrainable=True)\n","\n","\t\tsuper(proposal_Attention, self).build(input_shape)  # Be sure to call this somewhere!\n","\n","\tdef call(self, inputs, mask=None):\n","\n","\t\timg_emb = inputs[0]  # (batch_size, num_proposal, img_emb_size)\n","\t\ttext_emb = inputs[1]  # (batch_size, num_proposal, emb_size)\n","\n","\t\timg_emb_t = K.permute_dimensions(img_emb, (0, 2, 1)) # (batch_size, img_emb_size, num_proposal)\n","\n","\t\ttext_emb_t = K.permute_dimensions(text_emb, (0, 2, 1)) # (batch_size, emb_size, num_proposal)\n","\n","\t\tR = K.tanh(K.dot(self.Wu, img_emb_t)+K.dot(self.Wl, text_emb_t)) # (emb_size, batch_size, num_proposal)\n","\n","\t\tR_t = K.permute_dimensions(R, (1, 0, 2)) # (batch_size, emb_size, num_proposal)\n","\n","\t\tsoftmax_pi = K.softmax(K.permute_dimensions(K.dot(self.Wr, R_t), (1, 0, 2))) # (batch_size, emb_size, num_proposal)\n","\n","\t\timg_output = softmax_pi* softmax_pi\n","\n","\n","\t\timg_emb_t = K.permute_dimensions(img_emb, (0, 2, 1)) # (batch_size, img_emb_size, num_proposal)\n","\n","\t\ttext_emb_t = K.permute_dimensions(text_emb, (0, 2, 1)) # (batch_size, emb_size, num_proposal)\n","\n","\t\tR = K.tanh(K.dot(self.Wu, img_emb_t)+K.dot(self.Wl, text_emb_t)) # (emb_size, batch_size, num_proposal)\n","\n","\t\tR_t = K.permute_dimensions(R, (1, 0, 2)) # (batch_size, emb_size, num_proposal)\n","\n","\t\tsoftmax_pi = K.softmax(K.permute_dimensions(K.dot(self.Wr, R_t), (1, 0, 2))) # (batch_size, emb_size, num_proposal)\n","\n","\t\ttext_output = softmax_pi* softmax_pi\n","\n","\t\treturn img_output, text_output # (batch_size, g_embedding)\n","\n","\n","\tdef get_config(self):\n","\t\treturn super(proposal_Attention, self).get_config()\n","\n","\tdef compute_mask(self, inputs, mask=None):\n","\t\treturn None\n","\n","\tdef compute_output_shape(self, input_shape):\n","\t\toutput_shape = (input_shape[0][0], input_shape[0][-1])\n","\t\treturn output_shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k62b0GUZETSo"},"outputs":[],"source":["class my_coAttention_para(Layer):\n","\tdef __init__(self, dim_k, **kwargs):\n","\t\tsuper(my_coAttention_para, self).__init__(**kwargs)\n","\t\tself.dim_k = dim_k  # internal tensor dimension\n","\t\tself.supports_masking = True\n","\n","\tdef build(self, input_shape):\n","\t\tif not isinstance(input_shape, list):\n","\t\t\traise ValueError('A Co-Attention_para layer should be called '\n","\t\t\t\t\t\t\t\t'on a list of inputs.')\n","\t\tif len(input_shape) != 2:\n","\t\t\traise ValueError('A Co-Attention_para layer should be called on a list of 2 inputs.'\n","\t\t\t\t\t\t\t\t'Got '+str(len(input_shape))+'inputs.')\n","\t\tself.embedding_size = input_shape[0][-1]\n","\t\tself.num_region = input_shape[1][1]\n","\t\tself.seq_len = input_shape[0][1]\n","\t\t\"\"\"\n","\t\tnaming variables following the VQA paper\n","\t\t\"\"\"\n","\t\tself.Wi = self.add_weight(name=\"Wi\",\n","\t\t\t\t\t\t\t\t\tinitializer=\"random_normal\",\n","\t\t\t\t\t\t\t\t\t# initializer=\"ones\",\n","\t\t\t\t\t\t\t\t\tshape=(self.embedding_size, self.dim_k),\n","\t\t\t\t\t\t\t\t\ttrainable=True)\n","\t\tself.Wt = self.add_weight(name=\"Wt\",\n","\t\t\t\t\t\t\t\t\tinitializer=\"random_normal\",\n","\t\t\t\t\t\t\t\t\t# initializer=\"ones\",\n","\t\t\t\t\t\t\t\t\tshape=(self.embedding_size, self.dim_k),\n","\t\t\t\t\t\t\t\t\ttrainable=True)\n","\t\tself.Wpi = self.add_weight(name=\"Wpi\",\n","\t\t\t\t\t\t\t\t\tinitializer=\"random_normal\",\n","\t\t\t\t\t\t\t\t\t# initializer=\"ones\",\n","\t\t\t\t\t\t\t\t\tshape=(self.dim_k, 1),\n","\t\t\t\t\t\t\t\t\ttrainable=True)\n","\t\tself.Wi2 = self.add_weight(name=\"Wi2\",\n","\t\t\t\t\t\t\t\t\tinitializer=\"random_normal\",\n","\t\t\t\t\t\t\t\t\t# initializer=\"ones\",\n","\t\t\t\t\t\t\t\t\tshape=(self.embedding_size, self.dim_k),\n","\t\t\t\t\t\t\t\t\ttrainable=True)\n","\t\tself.Wt2 = self.add_weight(name=\"Wt2\",\n","\t\t\t\t\t\t\t\t\tinitializer=\"random_normal\",\n","\t\t\t\t\t\t\t\t\t# initializer=\"ones\",\n","\t\t\t\t\t\t\t\t\tshape=(self.embedding_size, self.dim_k),\n","\t\t\t\t\t\t\t\t\ttrainable=True)\n","\t\tself.Wpt = self.add_weight(name=\"Wpt\",\n","\t\t\t\t\t\t\t\t\tinitializer=\"random_normal\",\n","\t\t\t\t\t\t\t\t\t# initializer=\"ones\",\n","\t\t\t\t\t\t\t\t\tshape=(self.dim_k, 1),\n","\t\t\t\t\t\t\t\t\ttrainable=True)\n","\n","\t\tsuper(my_coAttention_para, self).build(input_shape)  # Be sure to call this somewhere!\n","\n","\tdef call(self, inputs, mask=None):\n","\t\ttFeature = inputs[0]\n","\t\tiFeature = inputs[1]\n","\t\tHt = K.dot(iFeature, self.Wi2) + K.dot(tFeature, self.Wt2)\n","\t\tHt = K.tanh(Ht)\n","\t\tPt = K.softmax(K.squeeze(K.dot(Ht, self.Wpt), axis=-1))\n","\t\tPt = K.permute_dimensions(K.repeat(Pt, self.embedding_size), (0, 2, 1))\n","\t\ttfeature = K.sum(Pt * tFeature, axis=1)\n","\n","\t\tHi = K.dot(iFeature, self.Wi) + K.dot(tFeature, self.Wt)\n","\t\tHi = K.tanh(Hi)\n","\t\tPi = K.softmax(K.squeeze(K.dot(Hi, self.Wpi), axis=-1))\n","\t\tPi = K.permute_dimensions(K.repeat(Pi, self.embedding_size), (0, 2, 1))\n","\t\tifeature = K.sum(Pi * iFeature, axis=1)\n","\n","\t\treturn tfeature+ifeature\n","\n","\n","\tdef get_config(self):\n","\t\treturn super(my_coAttention_para, self).get_config()\n","\n","\tdef compute_mask(self, inputs, mask=None):\n","\t\treturn None\n","\n","\tdef compute_output_shape(self, input_shape):\n","\t\toutput_shape = (input_shape[0][0], input_shape[0][-1])\n","\t\treturn output_shape\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-UGGFikZETSp"},"outputs":[],"source":["class text_user_Attention(Layer):\n","\tdef __init__(self, dim_k, **kwargs):\n","\t\tsuper(text_user_Attention, self).__init__(**kwargs)\n","\t\tself.dim_k = dim_k  # internal tensor dimension\n","\t\tself.supports_masking = True\n","\n","\tdef build(self, input_shape):\n","\t\tif not isinstance(input_shape, list):\n","\t\t\traise ValueError('A Co-Attention_para layer should be called '\n","\t\t\t\t\t\t\t\t'on a list of inputs.')\n","\t\tif len(input_shape) != 2:\n","\t\t\traise ValueError('A Co-Attention_para layer should be called on a list of 2 inputs.'\n","\t\t\t\t\t\t\t\t'Got '+str(len(input_shape))+'inputs.')\n","\t\tself.embedding_size = input_shape[0][-1]\n","\t\tself.num_region = input_shape[1][1]\n","\t\tself.seq_len = input_shape[0][1]\n","\t\t\"\"\"\n","\t\tnaming variables following the VQA paper\n","\t\t\"\"\"\n","\t\tself.Wu = self.add_weight(name=\"Wu\",\n","\t\t\t\t\t\t\t\t\tinitializer=\"random_normal\",\n","\t\t\t\t\t\t\t\t\t# initializer=\"ones\",\n","\t\t\t\t\t\t\t\t\tshape=(self.embedding_size, self.dim_k),\n","\t\t\t\t\t\t\t\t\ttrainable=True)\n","\t\tself.Wt = self.add_weight(name=\"Wt\",\n","\t\t\t\t\t\t\t\t\tinitializer=\"random_normal\",\n","\t\t\t\t\t\t\t\t\t# initializer=\"ones\",\n","\t\t\t\t\t\t\t\t\tshape=(self.embedding_size, self.dim_k),\n","\t\t\t\t\t\t\t\t\ttrainable=True)\n","\t\tself.Wpt = self.add_weight(name=\"Wpt\",\n","\t\t\t\t\t\t\t\t\tinitializer=\"random_normal\",\n","\t\t\t\t\t\t\t\t\t# initializer=\"ones\",\n","\t\t\t\t\t\t\t\t\tshape=(self.dim_k, 1),\n","\t\t\t\t\t\t\t\t\ttrainable=True)\n","\t\tself.Wu2 = self.add_weight(name=\"Wu2\",\n","\t\t\t\t\t\t\t\t\tinitializer=\"random_normal\",\n","\t\t\t\t\t\t\t\t\t# initializer=\"ones\",\n","\t\t\t\t\t\t\t\t\tshape=(self.embedding_size, self.dim_k),\n","\t\t\t\t\t\t\t\t\ttrainable=True)\n","\t\tself.Wt2 = self.add_weight(name=\"Wt2\",\n","\t\t\t\t\t\t\t\t\tinitializer=\"random_normal\",\n","\t\t\t\t\t\t\t\t\t# initializer=\"ones\",\n","\t\t\t\t\t\t\t\t\tshape=(self.embedding_size, self.dim_k),\n","\t\t\t\t\t\t\t\t\ttrainable=True)\n","\t\tself.Wpu = self.add_weight(name=\"Wpu\",\n","\t\t\t\t\t\t\t\t\tinitializer=\"random_normal\",\n","\t\t\t\t\t\t\t\t\t# initializer=\"ones\",\n","\t\t\t\t\t\t\t\t\tshape=(self.dim_k, 1),\n","\t\t\t\t\t\t\t\t\ttrainable=True)\n","\n","\t\tsuper(text_user_Attention, self).build(input_shape)  # Be sure to call this somewhere!\n","\n","\tdef call(self, inputs, mask=None):\n","\t\ttFeature = inputs[1]\n","\t\tuFeature = inputs[0]\n","\n","\t\tHt = K.dot(uFeature, self.Wu) + K.dot(tFeature, self.Wt)\n","\t\tHt = K.tanh(Ht)\n","\t\tPt = K.softmax(K.squeeze(K.dot(Ht, self.Wpt), axis=-1))\n","\t\tPt = K.permute_dimensions(K.repeat(Pt, self.embedding_size), (0, 2, 1))\n","\t\ttfeature = K.sum(Pt * tFeature, axis=1)\n","\n","\t\tHu = K.dot(uFeature, self.Wu2) + K.dot(tFeature, self.Wt2)\n","\t\tHu = K.tanh(Hu)\n","\t\tPu = K.softmax(K.squeeze(K.dot(Hu, self.Wpu), axis=-1))\n","\t\tPu = K.permute_dimensions(K.repeat(Pu, self.embedding_size), (0, 2, 1))\n","\t\tufeature = K.sum(Pu * uFeature, axis=1)\n","\n","\t\treturn tfeature+ufeature\n","\n","\tdef get_config(self):\n","\t\treturn super(text_user_Attention, self).get_config()\n","\n","\tdef compute_mask(self, inputs, mask=None):\n","\t\treturn None\n","\n","\tdef compute_output_shape(self, input_shape):\n","\t\toutput_shape = (input_shape[0][0], input_shape[0][-1])\n","\t\treturn output_shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0dN8pO5VETSp"},"outputs":[],"source":["class post_tag_Attention(Layer):\n","\tdef __init__(self, **kwargs):\n","\n","\t\tsuper(post_tag_Attention, self).__init__(**kwargs)\n","\n","\n","\tdef build(self, input_shape):\n","\n","\t\tif not isinstance(input_shape, list):\n","\t\t\traise ValueError('A Co-Attention_para layer should be called '\n","\t\t\t\t\t\t\t\t'on a list of inputs.')\n","\t\tif len(input_shape) != 2:\n","\t\t\traise ValueError('A Co-Attention_para layer should be called on a list of 2 inputs.'\n","\t\t\t\t\t\t\t\t'Got '+str(len(input_shape))+'inputs.')\n","\n","\t\tself.embedding_size = input_shape[0][-1] # 300 embedding size\n","\t\tself.num_region = input_shape[1][1] # 10 gamma\n","\t\tself.seq_len = input_shape[0][1] # 5/10 user/other post num\n","\n","\t\tself.Wh = self.add_weight(name=\"Wh\",\n","\t\t\t\t\t\t\t\t\tinitializer=\"random_normal\",\n","\t\t\t\t\t\t\t\t\t# initializer=\"ones\",\n","\t\t\t\t\t\t\t\t\tshape=(self.embedding_size, self.embedding_size),\n","\t\t\t\t\t\t\t\t\ttrainable=True)\n","\n","\t\tself.We = self.add_weight(name=\"We\",\n","\t\t\t\t\t\t\t\t\tinitializer=\"random_normal\",\n","\t\t\t\t\t\t\t\t\t# initializer=\"ones\",\n","\t\t\t\t\t\t\t\t\tshape=(self.embedding_size, self.embedding_size),\n","\t\t\t\t\t\t\t\t\ttrainable=True)\n","\t\tself.Wh2 = self.add_weight(name=\"Wh2\",\n","\t\t\t\t\t\t\t\t\tinitializer=\"random_normal\",\n","\t\t\t\t\t\t\t\t\t# initializer=\"ones\",\n","\t\t\t\t\t\t\t\t\tshape=(self.embedding_size, self.embedding_size),\n","\t\t\t\t\t\t\t\t\ttrainable=True)\n","\t\tself.Wf = self.add_weight(name=\"Wf\",\n","\t\t\t\t\t\t\t\t\tinitializer=\"random_normal\",\n","\t\t\t\t\t\t\t\t\t# initializer=\"ones\",\n","\t\t\t\t\t\t\t\t\tshape=(1, self.embedding_size),\n","\t\t\t\t\t\t\t\t\ttrainable=True)\n","\n","\t\tsuper(post_tag_Attention, self).build(input_shape)  # Be sure to call this somewhere!\n","\n","\tdef call(self, inputs, mask=None):\n","\n","\t\tEMu = inputs[0]  # (batch_size, post_num, g_embedding)\n","\t\tEHu = inputs[1]  # (batch_size, gamma_tag_num, g_embedding)\n","\n","\t\tEMu_t = K.permute_dimensions(EMu, (0, 2, 1)) # (batch_size, g_embedding, k_post_num)\n","\n","\t\tEHu_t = K.permute_dimensions(EHu, (0, 2, 1)) # (batch_size, g_embedding, gamma_tag_num)\n","\n","\t\tQ = K.tanh(K.batch_dot(K.dot(EMu, self.Wh), EHu_t)) # (batch_size, post_num, gamma_tag_num)\n","\t\tQ_t = K.permute_dimensions(Q, (0, 2, 1)) # (batch_size, gamma_tag_num, post_num)\n","\n","\t\tF1 = K.permute_dimensions(K.dot(self.We, EMu_t), (1,0,2)) # (g_embedding, batch_size, post_num) -> (batch_size, g_embedding, post_num)\n","\t\tF2 = K.permute_dimensions(K.dot(self.Wh2, EHu_t), (1,0,2)) # (g_embedding, batch_size, gamma_tag_num) -> (batch_size, g_embedding, gamma_tag_num)\n","\t\tF2_ = K.batch_dot(F2, Q_t) # (batch_size,g_embedding, post_num)\n","\t\tF = K.tanh(F1+F2_) # (batch_size, g_embedding, post_num)\n","\n","\t\tpi_ = K.permute_dimensions(K.dot(self.Wf, F), (1,0,2)) # (1,batch_size,5) -> (batch_size, 1, post_num)\n","\t\tpi = K.squeeze(pi_, axis= 1) # (batch_size, post_num)\n","\n","\t\tf = K.repeat(pi, self.embedding_size) # (batch_size, g_embedding, post_num)\n","\t\tfeature = K.sum(f * EMu_t, axis= -1) #(batch_size, g_embedding, post_num) -> (batch_size, g_embedding)\n","\n","\t\treturn feature # (batch_size, g_embedding)\n","\n","\n","\tdef get_config(self):\n","\t\treturn super(post_tag_Attention, self).get_config()\n","\n","\tdef compute_mask(self, inputs, mask=None):\n","\t\treturn None\n","\n","\tdef compute_output_shape(self, input_shape):\n","\t\toutput_shape = (input_shape[0][0], input_shape[0][-1])\n","\t\treturn output_shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7f1FrlzUETSq"},"outputs":[],"source":["def positional_encoding(seq_len, d_model):\n","    position = np.arange(seq_len)[:, np.newaxis]\n","    div_term = np.exp(np.arange(0, d_model, 2) * -(np.log(10000.0) / d_model))\n","\n","    pos_enc = np.zeros((seq_len, d_model))\n","    pos_enc[:, 0::2] = np.sin(position * div_term)\n","    pos_enc[:, 1::2] = np.cos(position * div_term)\n","    pos_enc = pos_enc[np.newaxis, ...]  # Add batch dimension\n","\n","    return tf.convert_to_tensor(pos_enc, dtype=tf.float32)"]},{"cell_type":"markdown","metadata":{"id":"hif0oE6BETSq"},"source":["#### Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XEsm7lyDETSr"},"outputs":[],"source":["def modelDef(lr):\n","\n","    # define input data shape\n","    inputs_img = Input(shape=(7, 7, 512)) #(480, 7, 7, 512)\n","    inputs_text = Input(shape=(49)) #(480, 49, 300)\n","    inputs_user_post = Input(shape=(top_u_post_num, 768)) #(480, 5, 768)\n","    inputs_other_post = Input(shape=(top_o_post_num, 768)) #(480, 10, 768)\n","    inputs_user_tag = Input(shape=(top_gamma_tag, num_tags)) #(480, 10, 3896)\n","    inputs_other_tag = Input(shape=(top_gamma_tag, num_tags)) #(480, 10, 3896)\n","\n","    G = [Input(batch_input_shape=(None, None), sparse=True)] # adjacency matrix (480, 480)\n","    G2 = [Input(batch_input_shape=(None, None), sparse=True)]\n","\n","    reshapeImg = Reshape(target_shape=(7*7, 512)) # (7, 7, 512) -> (49, 512)\n","    memoryImg = BatchMemory(49 , feature_size, 49, feature_size, 5)\n","    denseImg = Dense(feature_size, activation=\"tanh\", use_bias=True) # (49, 512 -> 49,300)\n","\n","    textEmbeddings = Embedding(input_dim=212003, output_dim=150, mask_zero=True, input_length=49)\n","    BiLSTM = Bidirectional(LSTM(units=150, return_sequences=True))\n","    denseText = Dense(feature_size, activation=\"tanh\", use_bias=True)\n","    #memoryText = BatchMemory(49 , feature_size, 49, feature_size, 5)\n","\n","    TagEmbeddings = Dense(768) # (10, 3896) -> (10,768)\n","\n","    # build attention model\n","    user_Att_layer = post_tag_Attention()\n","    other_Att_layer = post_tag_Attention()\n","\n","    # build multiple feature co-attention\n","    it_Att_layer = my_coAttention_para(dim_k=dim_k)\n","    tu_Att_layer = my_coAttention_para(dim_k=dim_k)\n","    iu_Att_layer = my_coAttention_para(dim_k=dim_k)\n","    io_Att_layer = my_coAttention_para(dim_k=dim_k)\n","    ou_Att_layer = my_coAttention_para(dim_k=dim_k)\n","    to_Att_layer = my_coAttention_para(dim_k=dim_k)\n","\n","    # build dense layer\n","    densePost = Dense(49*feature_size, activation=\"tanh\", use_bias=True) # (1*768) -> (49*300)\n","    denseOPost = Dense(49*feature_size, activation=\"tanh\", use_bias=True)\n","    reshapePost = Reshape(target_shape=(49, feature_size)) # (49*300) -> (49, 300)\n","\n","    #Ablation\n","    reshapeAdded = Reshape(target_shape=(1,49*feature_size)) # (49,64) -> (1,49*64)\n","    denseAdded = Dense(feature_size, activation=\"tanh\", use_bias=True) # (1,49*64) -> (1,64)\n","\n","    # reshape image feature (49*512 -> 49*300)\n","    iFeature = reshapeImg(inputs_img)\n","    iFeature = denseImg(iFeature)\n","    iFeature = memoryImg(iFeature)\n","\n","    # reshape text feature (768 -> 49*300)\n","    text_embeddings = textEmbeddings(inputs_text)\n","    tFeature = BiLSTM(text_embeddings+pos_encoding_repeated)\n","\n","    # encode post-tag data\n","    user_EHu = TagEmbeddings(inputs_user_tag)\n","    user_EMu = inputs_user_post\n","\n","    other_EMu = inputs_other_post\n","    other_EHu = TagEmbeddings(inputs_other_tag)\n","\n","    # post-tag attention\n","    uFeature = user_Att_layer([user_EMu, user_EHu])\n","    oFeature = other_Att_layer([other_EMu, other_EHu])\n","\n","    #uFeature = Reshape(target_shape=(1,top_u_post_num*768))(inputs_user_post)\n","    uFeature = densePost(uFeature)\n","    uFeature = reshapePost(uFeature)\n","\n","    #oFeature = Reshape(target_shape=(1,top_o_post_num*768))(inputs_other_post)\n","    oFeature = denseOPost(oFeature)\n","    oFeature = reshapePost(oFeature)\n","\n","    # multiple attention (less important feat., more important feat.)\n","\n","    it_vector = it_Att_layer([tFeature, iFeature])\n","    tu_vector = tu_Att_layer([uFeature, tFeature])\n","    iu_vector = iu_Att_layer([uFeature, iFeature])\n","    io_vector = io_Att_layer([oFeature, iFeature])\n","    to_vector = to_Att_layer([oFeature, tFeature])\n","    uo_vector = ou_Att_layer([oFeature, uFeature])\n","    added = Add()([it_vector, tu_vector, iu_vector, io_vector, to_vector, uo_vector])\n","\n","    # SAGE model for existing relation G\n","    H_G = Dropout(0.5)(added)\n","    H_G = GraphSageConv(64, name='GraphSage_G_1', aggregate='mean', activation='relu', kernel_regularizer=l2(5e-4))([H_G]+G)\n","    H_G = Dropout(0.5)(H_G)\n","    Y_G = GraphSageConv(num_tags, name='GraphSage_G_2', aggregate='mean', activation='softmax')([H_G]+G)\n","\n","    H_G2 = GraphSageConv(64, name='GraphSage_G2_1', aggregate='mean', activation='relu', kernel_regularizer=l2(5e-4))([H_G]+G2)\n","    H_G2 = Dropout(0.5)(H_G2)\n","    Y_G2 = GraphSageConv(num_tags, name='GraphSage_G2_2', aggregate='mean', activation='softmax')([H_G2]+G2)\n","\n","    # Combine outputs from both relations (e.g., concatenate or add)\n","    # Modify this line depending on how you want to combine them\n","    final_output = Y_G*0.95 + Y_G2*0.05\n","\n","\n","    model = Model(inputs=[inputs_img, inputs_text, inputs_user_post, inputs_other_post, inputs_user_tag, inputs_other_tag]+G+G2, outputs=[final_output])#model = Model(inputs=[inputs_img, inputs_text, inputs_user_post, inputs_other_post]+G, outputs=Y)\n","    sgd =  tf.keras.optimizers.SGD(learning_rate=lr, decay=1e-6, momentum=0.9, nesterov=True)\n","    model.compile(loss=myLossFunc, optimizer=sgd)\n","\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PpH0r0N4ETSr"},"outputs":[],"source":["def modelDef_wo(lr):\n","    #tf.config.run_functions_eagerly(True)\n","    # define input data shape\n","    inputs_img = Input(shape=(7, 7, 512)) #(480, 7, 7, 512)\n","    inputs_text = Input(shape=(49)) #(480, 49, 300)\n","    inputs_user_post = Input(shape=(top_u_post_num, 768)) #(480, 5, 768)\n","    inputs_other_post = Input(shape=(top_o_post_num, 768)) #(480, 10, 768)\n","    inputs_user_tag = Input(shape=(top_gamma_tag, num_tags)) #(480, 10, 3896)\n","    inputs_other_tag = Input(shape=(top_gamma_tag, num_tags)) #(480, 10, 3896)\n","\n","    G = [Input(batch_input_shape=(None, None), sparse=True)] # adjacency matrix (480, 480)\n","    G2 = [Input(batch_input_shape=(None, None), sparse=True)]\n","\n","    reshapeImg = Reshape(target_shape=(7*7, 512)) # (7, 7, 512) -> (49, 512)\n","    denseImg = Dense(feature_size, activation=\"tanh\", use_bias=True) # (49, 512 -> 49,300)\n","    memoryImg = BatchMemory(49 , feature_size, 49, feature_size, 5)\n","\n","\n","\n","    textEmbeddings = Embedding(input_dim=212003, output_dim=150, mask_zero=True, input_length=49)\n","    BiLSTM = Bidirectional(LSTM(units=150, return_sequences=True))\n","    #denseText = Dense(feature_size, activation=\"tanh\", use_bias=True)\n","    #memoryText = BatchMemory(49 , feature_size, 49, feature_size, 5)\n","\n","    TagEmbeddings = Dense(768) # (10, 3896) -> (10,768)\n","\n","    # build attention model\n","    user_Att_layer = post_tag_Attention()\n","    other_Att_layer = post_tag_Attention()\n","\n","    # build multiple feature co-attention\n","    it_Att_layer = my_coAttention_para(dim_k=dim_k)\n","    tu_Att_layer = text_user_Attention(dim_k=dim_k)\n","\n","    # build dense layer\n","    densePost = Dense(49*feature_size, activation=\"tanh\", use_bias=True) # (1*768) -> (49*300)\n","    denseOPost = Dense(49*feature_size, activation=\"tanh\", use_bias=True)\n","    reshapePost = Reshape(target_shape=(49, feature_size)) # (49*300) -> (49, 300)\n","\n","    #Ablation\n","    reshapeAdded = Reshape(target_shape=(1,49*feature_size)) # (49,64) -> (1,49*64)\n","    denseAdded = Dense(feature_size, activation=\"tanh\", use_bias=True) # (1,49*64) -> (1,64)\n","\n","    # build model\n","\n","    # reshape image feature (49*512 -> 49*300)\n","    iFeature = reshapeImg(inputs_img)\n","    iFeature = denseImg(iFeature)\n","    iFeature = memoryImg(iFeature)\n","\n","    # reshape text feature (768 -> 49*300)\n","    text_embeddings = textEmbeddings(inputs_text)\n","    tFeature = BiLSTM(text_embeddings)\n","\n","    # encode post-tag data\n","    user_EHu = TagEmbeddings(inputs_user_tag)\n","    user_EMu = inputs_user_post\n","\n","    other_EMu = inputs_other_post\n","    other_EHu = TagEmbeddings(inputs_other_tag)\n","\n","    # post-tag attention\n","    uFeature = user_Att_layer([user_EMu, user_EHu])\n","    oFeature = other_Att_layer([other_EMu, other_EHu])\n","\n","    #uFeature = Reshape(target_shape=(1,top_u_post_num*768))(inputs_user_post)\n","    uFeature = densePost(uFeature)\n","    uFeature = reshapePost(uFeature)\n","\n","    #oFeature = Reshape(target_shape=(1,top_o_post_num*768))(inputs_other_post)\n","    oFeature = denseOPost(oFeature)\n","    oFeature = reshapePost(oFeature)\n","\n","\n","    g_iFeature = iFeature\n","    g_tFeautre = tFeature\n","\n","    # multiple attention (less important feat., more important feat.)\n","\n","    it_vector = it_Att_layer([tFeature, iFeature])\n","    tu_vector = it_Att_layer([uFeature, tFeature])\n","    iu_vector = it_Att_layer([uFeature, iFeature])\n","    io_vector = it_Att_layer([oFeature, iFeature])\n","    to_vector = it_Att_layer([oFeature, tFeature])\n","    uo_vector = it_Att_layer([oFeature, uFeature]) # need to change attention layer\n","    #added = Add()([iu_vector,it_vector, tu_vector])\n","    added = Add()([io_vector,iu_vector,it_vector, tu_vector, to_vector, uo_vector])\n","\n","    added = Add()([iFeature,tFeature,uFeature,oFeature])\n","    #print(added)\n","    added = K.squeeze(Reshape(target_shape=(1,49*feature_size))(added), axis = 1)\n","    #print(added)\n","    added = Dense(feature_size, activation=\"tanh\", use_bias=True)(added)\n","\n","    # SAGE model for existing relation G\n","    H_G = Dropout(0.5)(added)\n","    H_G = GraphSageConv(64, name='GraphSage_G_1', aggregate='mean', activation='relu', kernel_regularizer=l2(5e-4))([H_G]+G)\n","    H_G = Dropout(0.5)(H_G)\n","    Y_G = GraphSageConv(num_tags, name='GraphSage_G_2', aggregate='mean', activation='softmax')([H_G]+G)\n","\n","    H_G2 = GraphSageConv(64, name='GraphSage_G2_1', aggregate='mean', activation='relu', kernel_regularizer=l2(5e-4))([H_G]+G2)\n","    H_G2 = Dropout(0.5)(H_G2)\n","    Y_G2 = GraphSageConv(num_tags, name='GraphSage_G2_2', aggregate='mean', activation='softmax')([H_G2]+G2)\n","\n","    # Combine outputs from both relations (e.g., concatenate or add)\n","    # Modify this line depending on how you want to combine them\n","    final_output =  Y_G2*0.05 + Y_G*0.95\n","    #print(final_output.shape)\n","    #final_output = tf.reshape(final_output, [500,-1])\n","    #print(final_output.shape)\n","\n","    model = Model(inputs=[inputs_img, inputs_text, inputs_user_post, inputs_other_post, inputs_user_tag, inputs_other_tag]+G+G2, outputs=final_output)#model = Model(inputs=[inputs_img, inputs_text, inputs_user_post, inputs_other_post]+G, outputs=Y)\n","    sgd =  tf.keras.optimizers.SGD(learning_rate=lr, decay=1e-6, momentum=0.9, nesterov=True)\n","    model.compile(loss=myLossFunc, optimizer=sgd)\n","\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"SAGqIVqMETSr"},"source":["### Run"]},{"cell_type":"markdown","metadata":{"id":"ntskP12pETS3"},"source":["### training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l_Kh-rqtETS3"},"outputs":[],"source":["model = modelDef(0.05)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AnGCT2W_ETS3"},"outputs":[],"source":["if __name__ == \"__main__\":\n","\n","    #with open(\"Preprocess_data/organized_np_data_%s.pkl\"%(today), \"rb\") as f:\n","    #    text_total, tags_total, ids_total, user_total, batch_total= pickle.load(f)\n","    num = ids_total.shape[0]  # post number\n","\n","    for top_K in [9]:\n","\n","        #model = modelDef()\n","        #model.load_weights(\"Model_data/model_best_0925-1_2layer.h5\")\n","        #model = tf.contrib.keras.models.load_model(\"Model_data/model_best_0414_2layer.h5\")\n","        #model.load_weights(\"Model_data/model_best_%s_2layer.h5\"%(date_num))\n","\n","        batch_size = 500\n","        num_test = 50\n","        num_train = batch_size - num_test\n","        num_in_graph_per_step = [[i for i in range(j, j + batch_size)] for j in range(0, batch_size*num_batch, batch_size)]\n","        train_num_array_per_step = [[i for i in range(j, j + num_train)] for j in range(0, batch_size*num_batch, batch_size)]\n","        test_num_array_per_step = [[i for i in range(j, j + num_test)] for j in range(num_train, batch_size*num_batch, batch_size)]\n","\n","        num_in_graph_per_step = np.array(num_in_graph_per_step)\n","        train_num_array_per_step = np.array(train_num_array_per_step)\n","        test_num_array_per_step = np.array(test_num_array_per_step)\n","\n","        print(\"num_in_graph_per_step: \", len(num_in_graph_per_step[0]))\n","        print(\"train_num_array_per_step: \", len(train_num_array_per_step[0]))\n","        print(\"test_num_array_per_step: \", len(test_num_array_per_step[0]))\n","        print(\"Start Training. Total steps: \", num_batch)\n","\n","        F = 0.0 # best F1 score\n","        wait = 0 # early stoping waiting round (var.)\n","        best_val_loss = 99999 # best loss value\n","        PATIENCE = 100 # early stoping waiting round number (para.)\n","\n","        adj_all = []\n","        t_adj_all = []\n","        for epoch in range(num_epoch):\n","\n","            #model.load_weights(\"Model_data/model_best_%s_2layer.h5\"%(date_num))\n","            batch_total_loss = 0.0\n","            skip_list = []\n","\n","            for i in range(num_batch):\n","\n","                batch_idx_train = range(0, len(train_num_array_per_step[i])) # numbers of training data per batch\n","                batch_train_mask = sample_mask(batch_idx_train, len(num_in_graph_per_step[i])) # mask training list (true/false)\n","\n","                # (batch_size,7,7,512) (batch_size,49,300) (batch_size,5,768) (batch_size,10,768) (batch_size,10,3896) (batch_size,10,3896)(batch_size,768)\n","                batch_img, batch_text, batch_u_post, batch_o_post, batch_u_tag, batch_o_tag, batch_text_id = get_batch_feature(num_in_graph_per_step[i], text_total_pad)\n","                if len(adj_all) != num_batch:\n","                    try:\n","                        # caculate img cosine similarity and get adjacency matrix\n","                        adj = img_adj_by_newcosine(batch_img,0.6)\n","                        adj_ = preprocess_adj(adj, True)\n","                        t_adj = adj_by_newcosine(batch_text,0.95)\n","                        t_adj_ = preprocess_adj(t_adj, True)\n","\n","\n","                        #batch_graph = [batch_img, batch_text, batch_u_post, batch_o_post, batch_u_tag, batch_o_tag, adj_]\n","                        batch_graph = [batch_img, batch_text_id, batch_u_post, batch_o_post, batch_u_tag, batch_o_tag, adj_, t_adj_]\n","                        adj_all.append(adj_)\n","                        t_adj_all.append(t_adj_)\n","                    except:\n","                        # if cannot get adjacency matrix\n","                        skip_list.append(i)\n","                        adj_all.append([])\n","                        print(\"oh\")\n","                        continue\n","                else:\n","                    batch_graph = [batch_img, batch_text_id, batch_u_post, batch_o_post, batch_u_tag, batch_o_tag, adj_all[i],t_adj_all[i]]\n","                    #batch_graph = [batch_img, batch_text, batch_u_post, batch_o_post, batch_u_tag, batch_o_tag, adj_all[i]]\n","                #print(batch_img.shape)\n","                # training data answer & testing data zero padding\n","                batch_train_labels = batch_train_label(tags_total, train_num_array_per_step[i], len(test_num_array_per_step[i]))\n","\n","                # train_on_batch( x=[img,text,u_post,o_post,u_tag,o_tag], y=training_ans(480,3896), batch_train_mask(480))\n","                history  = model.train_on_batch(batch_graph, batch_train_labels, sample_weight=batch_train_mask)\n","\n","                batch_total_loss += float(history)\n","                del batch_idx_train, batch_train_mask, batch_img, batch_text, batch_u_post, batch_o_post, batch_u_tag, batch_o_tag #,batch_train_labels\n","\n","\n","\n","            if epoch == 0:\n","                cnt = 0\n","                for i, sparr in enumerate(adj_all):\n","                    cnt += np.count_nonzero(np.array(sparr.toarray()))\n","                print(\"Total img edge num: \",cnt, \"         \")\n","\n","                cnt = 0\n","                for i, sparr in enumerate(t_adj_all):\n","                    cnt += np.count_nonzero(np.array(sparr.toarray()))\n","                print(\"Total text edge num: \",cnt, \"         \")\n","\n","\n","            # testing\n","            y_pred_all = []\n","            y_test_all = []\n","\n","            for i in range(num_batch):\n","\n","                # skip batches which being on skip_list\n","                if i in skip_list:\n","                    continue\n","                batch_img, batch_text, batch_u_post, batch_o_post, batch_u_tag, batch_o_tag, batch_text_id = get_batch_feature(num_in_graph_per_step[i],text_total_pad)\n","\n","                #batch_graph = [batch_img, batch_text, batch_u_post, batch_o_post, batch_u_tag, batch_o_tag, adj_all[i]] #[i]\n","                batch_graph = [batch_img, batch_text_id, batch_u_post, batch_o_post,batch_u_tag, batch_o_tag, adj_all[i],t_adj_all[i]]\n","                y_pred = model.predict_on_batch(batch_graph)\n","                y_pred_all.append(y_pred[len(train_num_array_per_step[i]):])\n","                batch_test_labels = batch_test_label(tags_total, test_num_array_per_step[i])\n","                y_test_all.append(batch_test_labels)\n","\n","                #acc, precision, recall, f1, f1_mean = evaluator(np.array(y_pred[len(train_num_array_per_step[i]):]),np.array(batch_test_labels), top_K)\n","                #print(\"batch %d, Epoch: %d, Loss: %.4f, accuracy: %.4f, precision: %.4f, recall: %.4f, f1: %.4f, f1_m: %.4f\" %\n","                #        (i, epoch, batch_total_loss, acc, float(precision), float(recall), float(f1),float(f1_mean)))\n","\n","                del batch_img, batch_text, batch_u_post, batch_o_post, batch_u_tag, batch_o_tag, batch_graph,batch_text_id\n","\n","            # need to add if batch > 1\n","            y_pred_all = np.concatenate(y_pred_all)\n","            y_test_all = np.concatenate(y_test_all)\n","\n","            # print the testing result\n","            acc, precision, recall, f1, f1_mean = evaluator(y_test_all, y_pred_all, top_K)\n","            print(\"Top %d, Epoch: %d, Loss: %.4f, accuracy: %.4f, precision: %.4f, recall: %.4f, f1: %.4f, f1_m: %.4f\" %\n","                    (top_K, epoch, batch_total_loss, acc, float(precision), float(recall), float(f1),float(f1_mean)))\n","\n","            # if getting the best f1 score than before, save model weights\n","            if f1_mean >= F:\n","                model.save_weights(\"Model_data/model_best_%s_2layer.h5\"%(date_num))\n","                res_file = open(\"Model_data/record_gcn_%s_2layer.txt\"%(date_num), \"a\")\n","                string = \"*Top %d, Epoch: %d,accuracy: %.4f, precision: %.4f, recall: %.4f, f1: %.4f \\n\" % (\n","                    top_K, epoch, acc, float(precision), float(recall), float(f1_mean))\n","                res_file.write(string)\n","                res_file.close()\n","                F = f1_mean\n","            else:\n","                res_file = open(\"Model_data/record_gcn_%s_2layer.txt\"%(date_num), \"a\")\n","                string = \"Top %d, Epoch: %d,accuracy: %.4f, precision: %.4f, recall: %.4f, f1: %.4f \\n\" % (\n","                    top_K, epoch, acc, float(precision), float(recall), float(f1_mean))\n","                res_file.write(string)\n","                res_file.close()\n","\n","            # Early stopping\n","            if batch_total_loss < best_val_loss:\n","                best_val_loss = batch_total_loss\n","                wait = 0\n","            else:\n","                if wait >= PATIENCE:\n","                    print('Epoch {}: early stopping'.format(epoch))\n","                    break\n","                wait += 1\n","\n","    print(\"Training Process Completed.\")\n","\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"},"vscode":{"interpreter":{"hash":"ee8c9e105572358416984fe81d7c3fdef676f76bcd26422621c6b11b71b606f4"}},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}